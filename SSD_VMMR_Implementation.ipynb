{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python generate_tfrecord.py -x [PATH_TO_IMAGES_FOLDER]/train -l [PATH_TO_ANNOTATIONS_FOLDER]/label_map.pbtxt -o [PATH_TO_ANNOTATIONS_FOLDER]/train.record\n",
    "# stuff in square bracket = to be filled. assumes train and label_map.pbtxt to be within said folders within the square bracket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python generate_tfrecord.py -x [PATH_TO_IMAGES_FOLDER]/test -l [PATH_TO_ANNOTATIONS_FOLDER]/label_map.pbtxt -o [PATH_TO_ANNOTATIONS_FOLDER]/test.record\n",
    "# assumes test and label_map.pbtxt to be within said folders within the square bracket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python model_main_tf2.py --model_dir=[PATH_TO_DOWNLOADED_MODELS_FILE]/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8 --pipeline_config_path=[PATH_TO_DOWNLOADED_MODELS_FILE]/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/pipeline.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python model_main_tf2.py --model_dir=[PATH_TO_DOWNLOADED_MODELS_FILE]/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8 --pipeline_config_path=[PATH_TO_DOWNLOADED_MODELS_FILE]/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/pipeline.config -checkpoint_dir=[PATH_TO_DOWNLOADED_MODELS_FILE]/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define variables for detection later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_MODEL_NAME = 'SSD_proto02' \n",
    "EXPORTED_MODEL_NAME = CUSTOM_MODEL_NAME + '_exp'\n",
    "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8'\n",
    "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
    "LABEL_MAP_NAME = 'labelmap.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {\n",
    "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
    "    'SCRIPTS_PATH': os.path.join('Tensorflow','workspace'),\n",
    "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
    "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
    "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','image'),\n",
    "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','trained_models',CUSTOM_MODEL_NAME,'checkpoint'), \n",
    "    'EXPORTED_CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','exported_models',EXPORTED_MODEL_NAME,'checkpoint'), \n",
    "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','exported_models',EXPORTED_MODEL_NAME), \n",
    "    'PROTOC_PATH':os.path.join('Protobuf','bin')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\n",
    "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','trained_models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'EXPORTED_PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','exported_models', EXPORTED_MODEL_NAME, 'pipeline.config'),\n",
    "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        print(path ,\"not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import config_util\n",
    "import cv2 \n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "from matplotlib import pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-06 16:09:57.967067: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-06 16:09:57.998729: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-06 16:09:57.999153: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-06 16:09:57.999982: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-10-06 16:09:58.030076: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-06 16:09:58.030637: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-06 16:09:58.030982: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-06 16:09:58.802075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-06 16:09:58.802421: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-06 16:09:58.802659: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-06 16:09:58.802862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2462 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "# restore exported model\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(paths['EXPORTED_CHECKPOINT_PATH'], 'ckpt-0')).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define variables for use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define image path and create index based on labelmap classes\n",
    "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])\n",
    "IMAGE_PATH = os.path.join(paths['IMAGE_PATH'], 'test', 'honda_crv_4thGen (56).jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define variables for use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03345370292663574\n"
     ]
    }
   ],
   "source": [
    "#read the image\n",
    "img = cv2.imread(IMAGE_PATH)\n",
    "image_np = np.array(img)\n",
    "\n",
    "#expand the dimensions of the image so that it is usable by tensorflow\n",
    "image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "#convert numpy array to tensor object\n",
    "input_tensor = tf.convert_to_tensor(image_np_expanded, dtype=tf.float32)\n",
    "\n",
    "#run detection and record time taken\n",
    "start = time.time()\n",
    "detections = detect_fn(input_tensor)\n",
    "end = time.time()\n",
    "dur = end - start\n",
    "print(dur)\n",
    "\n",
    "#draws the bounding boxes based on object detections\n",
    "num_detections = int(detections.pop('num_detections'))\n",
    "detections = {key: value[0, :num_detections].numpy()\n",
    "              for key, value in detections.items()}\n",
    "detections['num_detections'] = num_detections\n",
    "\n",
    "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "label_id_offset = 1\n",
    "image_np_with_detections = image_np.copy()\n",
    "\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "            image_np_with_detections,\n",
    "            detections['detection_boxes'],\n",
    "            detections['detection_classes']+label_id_offset,\n",
    "            detections['detection_scores'],\n",
    "            category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            max_boxes_to_draw=5,\n",
    "            min_score_thresh=.8,\n",
    "            agnostic_mode=False)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x47504a4d/'MJPG' is not supported with codec id 7 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 seconds of video processed.\n",
      "2.0 seconds of video processed.\n",
      "3.0 seconds of video processed.\n",
      "4.0 seconds of video processed.\n",
      "5.0 seconds of video processed.\n",
      "6.0 seconds of video processed.\n",
      "7.0 seconds of video processed.\n",
      "8.0 seconds of video processed.\n",
      "9.0 seconds of video processed.\n",
      "10.0 seconds of video processed.\n",
      "11.0 seconds of video processed.\n",
      "12.0 seconds of video processed.\n",
      "13.0 seconds of video processed.\n",
      "14.0 seconds of video processed.\n",
      "15.0 seconds of video processed.\n",
      "16.0 seconds of video processed.\n",
      "17.0 seconds of video processed.\n",
      "18.0 seconds of video processed.\n",
      "19.0 seconds of video processed.\n",
      "20.0 seconds of video processed.\n",
      "21.0 seconds of video processed.\n",
      "22.0 seconds of video processed.\n",
      "23.0 seconds of video processed.\n",
      "24.0 seconds of video processed.\n",
      "25.0 seconds of video processed.\n",
      "26.0 seconds of video processed.\n",
      "27.0 seconds of video processed.\n",
      "28.0 seconds of video processed.\n",
      "29.0 seconds of video processed.\n",
      "30.0 seconds of video processed.\n",
      "31.0 seconds of video processed.\n",
      "32.0 seconds of video processed.\n",
      "33.0 seconds of video processed.\n",
      "34.0 seconds of video processed.\n",
      "35.0 seconds of video processed.\n",
      "36.0 seconds of video processed.\n",
      "37.0 seconds of video processed.\n",
      "38.0 seconds of video processed.\n",
      "39.0 seconds of video processed.\n",
      "40.0 seconds of video processed.\n",
      "41.0 seconds of video processed.\n",
      "42.0 seconds of video processed.\n",
      "43.0 seconds of video processed.\n",
      "44.0 seconds of video processed.\n",
      "45.0 seconds of video processed.\n",
      "46.0 seconds of video processed.\n",
      "47.0 seconds of video processed.\n",
      "48.0 seconds of video processed.\n",
      "49.0 seconds of video processed.\n",
      "50.0 seconds of video processed.\n",
      "51.0 seconds of video processed.\n",
      "52.0 seconds of video processed.\n",
      "53.0 seconds of video processed.\n",
      "54.0 seconds of video processed.\n",
      "55.0 seconds of video processed.\n",
      "56.0 seconds of video processed.\n",
      "57.0 seconds of video processed.\n",
      "58.0 seconds of video processed.\n",
      "59.0 seconds of video processed.\n",
      "60.0 seconds of video processed.\n",
      "61.0 seconds of video processed.\n",
      "62.0 seconds of video processed.\n",
      "63.0 seconds of video processed.\n",
      "64.0 seconds of video processed.\n",
      "65.0 seconds of video processed.\n",
      "66.0 seconds of video processed.\n",
      "67.0 seconds of video processed.\n",
      "68.0 seconds of video processed.\n",
      "69.0 seconds of video processed.\n",
      "70.0 seconds of video processed.\n",
      "71.0 seconds of video processed.\n",
      "72.0 seconds of video processed.\n",
      "73.0 seconds of video processed.\n",
      "74.0 seconds of video processed.\n",
      "75.0 seconds of video processed.\n",
      "76.0 seconds of video processed.\n",
      "77.0 seconds of video processed.\n",
      "78.0 seconds of video processed.\n",
      "79.0 seconds of video processed.\n",
      "80.0 seconds of video processed.\n",
      "81.0 seconds of video processed.\n",
      "82.0 seconds of video processed.\n",
      "83.0 seconds of video processed.\n",
      "84.0 seconds of video processed.\n",
      "85.0 seconds of video processed.\n",
      "86.0 seconds of video processed.\n",
      "87.0 seconds of video processed.\n",
      "88.0 seconds of video processed.\n",
      "89.0 seconds of video processed.\n",
      "90.0 seconds of video processed.\n",
      "91.0 seconds of video processed.\n",
      "92.0 seconds of video processed.\n",
      "93.0 seconds of video processed.\n",
      "94.0 seconds of video processed.\n",
      "95.0 seconds of video processed.\n",
      "96.0 seconds of video processed.\n",
      "97.0 seconds of video processed.\n",
      "98.0 seconds of video processed.\n",
      "99.0 seconds of video processed.\n",
      "100.0 seconds of video processed.\n",
      "101.0 seconds of video processed.\n",
      "102.0 seconds of video processed.\n",
      "103.0 seconds of video processed.\n",
      "104.0 seconds of video processed.\n",
      "105.0 seconds of video processed.\n",
      "106.0 seconds of video processed.\n",
      "107.0 seconds of video processed.\n",
      "108.0 seconds of video processed.\n",
      "109.0 seconds of video processed.\n",
      "110.0 seconds of video processed.\n",
      "111.0 seconds of video processed.\n",
      "112.0 seconds of video processed.\n",
      "113.0 seconds of video processed.\n",
      "114.0 seconds of video processed.\n",
      "115.0 seconds of video processed.\n",
      "116.0 seconds of video processed.\n",
      "117.0 seconds of video processed.\n",
      "118.0 seconds of video processed.\n",
      "119.0 seconds of video processed.\n",
      "120.0 seconds of video processed.\n",
      "121.0 seconds of video processed.\n",
      "122.0 seconds of video processed.\n",
      "123.0 seconds of video processed.\n",
      "124.0 seconds of video processed.\n",
      "125.0 seconds of video processed.\n",
      "126.0 seconds of video processed.\n",
      "127.0 seconds of video processed.\n",
      "128.0 seconds of video processed.\n",
      "129.0 seconds of video processed.\n",
      "130.0 seconds of video processed.\n",
      "131.0 seconds of video processed.\n",
      "132.0 seconds of video processed.\n",
      "133.0 seconds of video processed.\n",
      "134.0 seconds of video processed.\n",
      "135.0 seconds of video processed.\n",
      "136.0 seconds of video processed.\n",
      "137.0 seconds of video processed.\n",
      "138.0 seconds of video processed.\n",
      "139.0 seconds of video processed.\n",
      "140.0 seconds of video processed.\n",
      "141.0 seconds of video processed.\n",
      "142.0 seconds of video processed.\n",
      "143.0 seconds of video processed.\n",
      "144.0 seconds of video processed.\n",
      "145.0 seconds of video processed.\n",
      "146.0 seconds of video processed.\n",
      "147.0 seconds of video processed.\n",
      "148.0 seconds of video processed.\n",
      "149.0 seconds of video processed.\n",
      "150.0 seconds of video processed.\n",
      "151.0 seconds of video processed.\n",
      "152.0 seconds of video processed.\n",
      "153.0 seconds of video processed.\n",
      "154.0 seconds of video processed.\n",
      "155.0 seconds of video processed.\n",
      "156.0 seconds of video processed.\n",
      "157.0 seconds of video processed.\n",
      "158.0 seconds of video processed.\n",
      "159.0 seconds of video processed.\n",
      "160.0 seconds of video processed.\n",
      "161.0 seconds of video processed.\n",
      "162.0 seconds of video processed.\n",
      "163.0 seconds of video processed.\n",
      "164.0 seconds of video processed.\n",
      "165.0 seconds of video processed.\n",
      "166.0 seconds of video processed.\n",
      "167.0 seconds of video processed.\n",
      "168.0 seconds of video processed.\n",
      "169.0 seconds of video processed.\n",
      "170.0 seconds of video processed.\n",
      "171.0 seconds of video processed.\n",
      "172.0 seconds of video processed.\n",
      "173.0 seconds of video processed.\n",
      "174.0 seconds of video processed.\n",
      "175.0 seconds of video processed.\n",
      "176.0 seconds of video processed.\n",
      "177.0 seconds of video processed.\n",
      "178.0 seconds of video processed.\n",
      "179.0 seconds of video processed.\n",
      "180.0 seconds of video processed.\n",
      "181.0 seconds of video processed.\n",
      "182.0 seconds of video processed.\n",
      "total inference duration in seconds:  144.31029510498047\n",
      "fps 37.918292634765386\n"
     ]
    }
   ],
   "source": [
    "VIDEO_PATH = os.path.join(paths['IMAGE_PATH'], 'videos', 'perodua_axia.mp4')\n",
    "OUTPUT_VIDEO_PATH = os.path.join(paths['IMAGE_PATH'], 'output', 'output_axia_SSD_proto01.mp4')\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "print(cap.isOpened())\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "out = cv2.VideoWriter(OUTPUT_VIDEO_PATH,cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'), 30, (frame_width,frame_height))\n",
    "count = 0\n",
    "totdur = 0\n",
    "\n",
    "while cap.isOpened(): \n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if (not ret):\n",
    "        break\n",
    "    \n",
    "    image_np = np.array(frame)\n",
    "    \n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    start = time.time()\n",
    "    detections = detect_fn(input_tensor)\n",
    "    end = time.time()\n",
    "    dur = end - start\n",
    "    totdur += dur\n",
    "    \n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np_with_detections,\n",
    "                detections['detection_boxes'],\n",
    "                detections['detection_classes']+label_id_offset,\n",
    "                detections['detection_scores'],\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                max_boxes_to_draw=5,\n",
    "                min_score_thresh=.8,\n",
    "                agnostic_mode=False)\n",
    "\n",
    "    out.write(image_np_with_detections)\n",
    "    \n",
    "    count += 1\n",
    "    if count%30 == 0:\n",
    "        print((count/30),\"seconds of video processed.\")\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "print(\"total inference duration in seconds: \", totdur)\n",
    "print(\"fps\", count/totdur)\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
